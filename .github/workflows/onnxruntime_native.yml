name: publish onnxruntime native

on:
  # To trigger this workflow manually, you can use the following curl command:
  # curl -XPOST -u "USERNAME:PERSONAL_TOKEN" -H "Accept: application/vnd.github.everest-preview+json" -H "Content-Type: application/json" https://api.github.com/repos/awslabs/djl/dispatches --data '{"event_type": "onnxruntime-native-build"}'

  # Make sure you create your personal token with repo access. Follow steps in
  # https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line
  # to create your personal token.
  repository_dispatch:
    types: [onnxruntime-native-build]

jobs:
  build:
    runs-on: ${{ matrix.operating-system }}
    strategy:
      matrix:
        operating-system: [ubuntu-18.04, macos-latest]
    env:
      ONNX_RUNTIME_TAG_VERSION:    "v1.3.0"
      ONNX_RUNTIME_VERSION: "1.3.0"
    steps:
      - uses: actions/checkout@v1
      - name: Set up JDK 1.8
        uses: actions/setup-java@v1
        with:
          java-version: 1.8
      - name: Set up Python3
        uses: actions/setup-python@v1
        with:
          python-version: '3.x'
      - name: clone onnx runtime
        run: git clone https://github.com/microsoft/onnxruntime onnxruntime_tmp -b "${ONNX_RUNTIME_TAG_VERSION}" --recursive
      - name: install Python Dependencies
        run: pip install flake8
      - name: Copy gradle files
        run: |
          cp gradlew onnxruntime_tmp/java
          cp -R gradle onnxruntime_tmp/java
      - name: Start building
        run: |
          cd onnxruntime_tmp
          bash build.sh --config Release --build_shared_lib --parallel --build_java
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2
      - name: Copy files to S3 with the AWS CLI
        run: |
          aws s3 sync onnxruntime_tmp/java/build/libs s3://djl-ai/publish/onnxruntime-${ONNX_RUNTIME_VERSION}/${{ runner.os }}/cpu
