{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your first deep learning neural network\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is the first of our [beginner tutorial series](https://github.com/awslabs/djl/tree/master/jupyter/tutorial) that will take you through creating, training, and running inference on a neural network. In this tutorial, you will learn how to use the built-in `Block` to create your first neural network. We will be building one of the simplest deep learning networks, a Multilayer Perceptron (MLP). For more information, see [Multilayer Perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron).\n",
    "\n",
    "## Block API\n",
    "\n",
    "[Blocks](https://javadoc.djl.ai/api/0.2.1/index.html?ai/djl/nn/Block.html) serve a purpose similar to functions that convert an input `NDList` to an output `NDList`. They can represent single operations, parts of a neural network, and even the whole neural network. What makes blocks special is that they contain a number of parameters that are used in their function and are trained during deep learning. As these parameters are trained, the function represented by the blocks get more and more accurate.\n",
    "\n",
    "When building these block functions, the easiest way is to use composition. Similar to how functions are built by calling other functions, blocks can be built by combining other blocks. We refer to the containing block as the parent and the sub-blocks as the children.\n",
    "\n",
    "\n",
    "## Step 1: Setup development environment\n",
    "\n",
    "### Installation\n",
    "\n",
    "This tutorial requires the installation of the Java Jupyter Kernel. To install the kernel, see the [Jupyter README](https://github.com/awslabs/djl/blob/master/jupyter/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mavenRepo snapshots https://oss.sonatype.org/content/repositories/snapshots/\n",
    "\n",
    "%maven ai.djl:api:0.3.0-SNAPSHOT\n",
    "%maven org.slf4j:slf4j-api:1.7.26\n",
    "%maven org.slf4j:slf4j-simple:1.7.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai.djl.*;\n",
    "import ai.djl.nn.*;\n",
    "import ai.djl.nn.core.*;\n",
    "import ai.djl.training.*;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Determine your input and output size\n",
    "\n",
    "The MLP model uses a one dimensional vector as the input and the output. You should determine the appropriate size of this vector based on your input data and what you will use the output of the model for. In a later tutorial, we will use a 28x28 image as the input and a 10 class classification as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "long inputSize = 28*28;\n",
    "long outputSize = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a **SequentialBlock**\n",
    "\n",
    "We provide several helpers to make it easy to build common block structures. For the MLP we will use the [SequentialBlock](https://javadoc.djl.ai/api/0.2.1/index.html?ai/djl/nn/SequentialBlock.html), a container block whose children form a chain of blocks with each child block feeding its output in sequence to the next.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SequentialBlock block = new SequentialBlock();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add blocks to SequentialBlock\n",
    "\n",
    "An MLP is organized into several layers. Each layer is composed of a [Linear Block](https://javadoc.djl.ai/api/0.2.1/index.html?ai/djl/nn/core/Linear.html) and a non-linear activation function. We will use the popular [ReLU](https://javadoc.djl.ai/api/0.2.1/ai/djl/nn/Activation.html#reluBlock--) as our activation function.\n",
    "\n",
    "The first layer and last layers have fixed sizes depending on your desired input and output size. However, you are free to choose the number and sizes of the middle layers in the network. We will create a smaller MLP with two middle layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "\tLambda()\n",
       "\tLinear(Uninitialized)\n",
       "\tLambda()\n",
       "\tLinear(Uninitialized)\n",
       "\tLambda()\n",
       "\tLinear(Uninitialized)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.add(Blocks.batchFlattenBlock(inputSize));\n",
    "block.add(new Linear.Builder().setOutChannels(128).build());\n",
    "block.add(Activation.reluBlock());\n",
    "block.add(new Linear.Builder().setOutChannels(64).build());\n",
    "block.add(Activation.reluBlock());\n",
    "block.add(new Linear.Builder().setOutChannels(outputSize).build());\n",
    "\n",
    "block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Now that you've successfully created your first neural network, you can use this network to train your model.\n",
    "\n",
    "Next chapter: [Train your first model](train_your_first_model.ipynb)\n",
    "\n",
    "You can find the complete source code for this tutorial in the [model zoo](https://github.com/awslabs/djl/blob/master/model-zoo/src/main/java/ai/djl/basicmodelzoo/cv/classification/Mlp.java)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "12.0.2+10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
