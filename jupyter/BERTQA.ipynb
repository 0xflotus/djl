{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joule BERT Inference Demo\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, you'll walk through the BERT QA model trained by MXNet. \n",
    "You can provide a question and a paragraph containing the answer to the model. The model is then able to find the best answer from the answer paragraph.\n",
    "\n",
    "Example:\n",
    "```text\n",
    "Q: When did BBC Japan start broadcasting?\n",
    "```\n",
    "\n",
    "Answer paragraph:\n",
    "```text\n",
    "BBC Japan was a general entertainment channel, which operated between December 2004 and April 2006.\n",
    "It ceased operations after its Japanese distributor folded.\n",
    "```\n",
    "And it picked the right answer:\n",
    "```text\n",
    "A: December 2004\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Configure the maven repository\n",
    "The following command define the repo to fetch the Joule package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mavenRepo s3 https://joule.s3.amazonaws.com/repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Import the required library\n",
    "Please run the following command to load the Joule package and its dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%maven software.amazon.ai:joule-api:0.2.0-SNAPSHOT\n",
    "%maven org.apache.mxnet:mxnet-joule:0.2.0-SNAPSHOT\n",
    "%maven org.slf4j:slf4j-api:1.7.26\n",
    "%maven org.slf4j:slf4j-simple:1.7.26\n",
    "%maven net.java.dev.jna:jna:5.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the problem with gradle integration with Jupyter, we need to manually load MXNet pacakge from pom.\n",
    "\n",
    "Please specify the MXNet package you would like to use by changing the `<classifier>` tag. Here are the two options you can go with for Mac and Linux system.\n",
    "\n",
    "#### Mac OS\n",
    "```\n",
    "<classifier>osx-x86_64</classifier>\n",
    "```\n",
    "\n",
    "#### Ubuntu 16.04/Cent OS 7/Amazon Linux\n",
    "```\n",
    "<classifier>linux-x86_64</classifier>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "  <repositories>\n",
    "    <repository>\n",
    "      <id>joule</id>\n",
    "      <url>https://joule.s3.amazonaws.com/repo</url>\n",
    "    </repository>\n",
    "  </repositories>\n",
    "\n",
    "  <dependencies>\n",
    "    <dependency>\n",
    "      <groupId>org.apache.mxnet</groupId>\n",
    "      <artifactId>mxnet-native-mkl</artifactId>\n",
    "      <version>1.5.0-SNAPSHOT</version>\n",
    "      <classifier>osx-x86_64</classifier>\n",
    "    </dependency>\n",
    "  </dependencies>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the library that going to be used in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.charset.StandardCharsets;\n",
    "import java.nio.file.*;\n",
    "import java.util.*;\n",
    "import java.io.*;\n",
    "import com.google.gson.Gson;\n",
    "import com.google.gson.GsonBuilder;\n",
    "import com.google.gson.annotations.SerializedName;\n",
    "\n",
    "import java.io.IOException;\n",
    "import java.nio.file.Path;\n",
    "import java.util.List;\n",
    "import org.slf4j.Logger;\n",
    "import software.amazon.ai.Context;\n",
    "import software.amazon.ai.Model;\n",
    "import software.amazon.ai.TranslateException;\n",
    "import software.amazon.ai.Translator;\n",
    "import software.amazon.ai.TranslatorContext;\n",
    "import software.amazon.ai.inference.Predictor;\n",
    "import software.amazon.ai.metric.Metrics;\n",
    "import software.amazon.ai.ndarray.NDArray;\n",
    "import software.amazon.ai.ndarray.NDList;\n",
    "import software.amazon.ai.ndarray.NDManager;\n",
    "import software.amazon.ai.ndarray.types.DataDesc;\n",
    "import software.amazon.ai.ndarray.types.DataType;\n",
    "import software.amazon.ai.ndarray.types.Shape;\n",
    "import software.amazon.ai.util.Utils;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Load the BertDataParser\n",
    "The Class `BertDataParser` is used to load the vocabulary that Bert Embedding being trained. Please do not change the content of the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * This is the Utility for pre-processing the data for Bert Model.\n",
    " *\n",
    " * <p>You can use this utility to parse vocabulary JSON into Java Array and Dictionary, clean and\n",
    " * tokenize sentences and pad the text\n",
    " */\n",
    "\n",
    "public class BertDataParser {\n",
    "\n",
    "    private static final Gson GSON = new GsonBuilder().create();\n",
    "    private static final Pattern PATTERN = Pattern.compile(\"(\\\\S+?)([.,?!])?(\\\\s+|$)\");\n",
    "\n",
    "    @SerializedName(\"token_to_idx\")\n",
    "    private Map<String, Integer> token2idx;\n",
    "\n",
    "    @SerializedName(\"idx_to_token\")\n",
    "    private List<String> idx2token;\n",
    "\n",
    "    /**\n",
    "    \n",
    "     * Parse the Vocabulary to JSON files [PAD], [CLS], [SEP], [MASK], [UNK] are reserved tokens.\n",
    "     *\n",
    "     * @param is the {@code InputStream} for the vocab.json\n",
    "     * @return instance of {@code BertDataParser}\n",
    "     * @throws IllegalStateException if failed read from {@code InputStream}\n",
    "     */\n",
    "    public static BertDataParser parse(InputStream is) {\n",
    "        try (Reader reader = new InputStreamReader(is, StandardCharsets.UTF_8)) {\n",
    "            return GSON.fromJson(reader, BertDataParser.class);\n",
    "        } catch (IOException e) {\n",
    "            throw new IllegalStateException(e);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Tokenize the input, split all kinds of whitespace and Separate the end of sentence symbol: .\n",
    "     * , ? !\n",
    "     *\n",
    "     * @param input The input string\n",
    "     * @return List of tokens\n",
    "     */\n",
    "    public static List<String> tokenizer(String input) {\n",
    "        List<String> ret = new LinkedList<>();\n",
    "\n",
    "        Matcher m = PATTERN.matcher(input);\n",
    "        while (m.find()) {\n",
    "            ret.add(m.group(1));\n",
    "            String token = m.group(2);\n",
    "            if (token != null) {\n",
    "                ret.add(token);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return ret;\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Pad the tokens to the required length.\n",
    "     *\n",
    "     * @param <E> the type of the List\n",
    "     * @param tokens input tokens\n",
    "     * @param padItem things to pad at the end\n",
    "     * @param num total length after padding\n",
    "     * @return List of padded tokens\n",
    "     */\n",
    "    public static <E> List<E> pad(List<E> tokens, E padItem, int num) {\n",
    "        if (tokens.size() >= num) {\n",
    "            return tokens;\n",
    "        }\n",
    "        List<E> padded = new ArrayList<>(num);\n",
    "        padded.addAll(tokens);\n",
    "        for (int i = tokens.size(); i < num; ++i) {\n",
    "            padded.add(padItem);\n",
    "        }\n",
    "        return padded;\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Form the token types List [0000...1111...000] where all questions are 0 and answers are 1.\n",
    "     *\n",
    "     * @param question question tokens\n",
    "     * @param answer answer tokens\n",
    "     * @param seqLength sequence length\n",
    "     * @return List of tokenTypes\n",
    "     */\n",
    "    public static List<Float> getTokenTypes(\n",
    "            List<String> question, List<String> answer, int seqLength) {\n",
    "        List<Float> qaEmbedded = new ArrayList<>();\n",
    "        qaEmbedded = pad(qaEmbedded, 0f, question.size() + 2);\n",
    "        qaEmbedded.addAll(pad(new ArrayList<>(), 1f, answer.size()));\n",
    "        return pad(qaEmbedded, 0f, seqLength);\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Form tokens with separation that can be used for BERT.\n",
    "     *\n",
    "     * @param question question tokens\n",
    "     * @param answer answer tokens\n",
    "     * @param seqLength sequence length\n",
    "     * @return List of tokenTypes\n",
    "     */\n",
    "    public static List<String> formTokens(\n",
    "            List<String> question, List<String> answer, int seqLength) {\n",
    "        // make BERT pre-processing standard\n",
    "        List<String> tokens = new ArrayList<>(question);\n",
    "        tokens.add(\"[SEP]\");\n",
    "        tokens.add(0, \"[CLS]\");\n",
    "        answer.add(\"[SEP]\");\n",
    "        tokens.addAll(answer);\n",
    "        tokens.add(\"[SEP]\");\n",
    "        return pad(tokens, \"[PAD]\", seqLength);\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Convert tokens to indexes.\n",
    "     *\n",
    "     * @param tokens input tokens\n",
    "     * @return List of indexes\n",
    "     */\n",
    "    public List<Integer> token2idx(List<String> tokens) {\n",
    "        List<Integer> indexes = new ArrayList<>();\n",
    "        for (String token : tokens) {\n",
    "            if (token2idx.containsKey(token)) {\n",
    "                indexes.add(token2idx.get(token));\n",
    "            } else {\n",
    "                indexes.add(token2idx.get(\"[UNK]\"));\n",
    "            }\n",
    "        }\n",
    "        return indexes;\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Convert indexes to tokens.\n",
    "     *\n",
    "     * @param indexes List of indexes\n",
    "     * @return List of tokens\n",
    "     */\n",
    "    public List<String> idx2token(List<Integer> indexes) {\n",
    "        List<String> tokens = new ArrayList<>();\n",
    "        for (int index : indexes) {\n",
    "            tokens.add(idx2token.get(index));\n",
    "        }\n",
    "        return tokens;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this point, we finish all of the preparations. Let's start writing code to do inference with this example.\n",
    "\n",
    "### Step 4 Preparing for the model and input\n",
    "\n",
    "The model would require three inputs:\n",
    "\n",
    "- word indices: The index of each word in a sentence\n",
    "- word types: The type index of the word. All Questions will be labelled as 0 and all Answers will be labelled as 1s.\n",
    "- sequence length: We need to limit the length of the input, in our case, the length is 384\n",
    "- valid length: The length of the question and answer tokens\n",
    "\n",
    "**Firstly, let's load the input**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "var question = \"When did BBC Japan start broadcasting?\";\n",
    "var answerMaterial = \"BBC Japan was a general entertainment Channel.\\nWhich operated between December 2004 and April 2006.\\nIt ceased operations after its Japanese distributor folded.\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Secondly, we can load the model and all its artifacts**\n",
    "\n",
    "This download process may take a while based on the network speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "public void download(String url, String fileName) throws IOException {\n",
    "  URL downloadUrl = new URL(url);\n",
    "  String tempDir = System.getProperty(\"java.io.tmpdir\");\n",
    "  Path tmp = Paths.get(tempDir).resolve(\"bert\");\n",
    "  Path dest = tmp.resolve(fileName);\n",
    "  if (Files.exists(dest)) {\n",
    "    return;\n",
    "  }\n",
    "  Files.createDirectories(tmp.toAbsolutePath());\n",
    "  try (InputStream is = downloadUrl.openStream()) {\n",
    "    Files.copy(is, dest);\n",
    "  }\n",
    "}\n",
    "\n",
    "download(\"https://s3.us-east-2.amazonaws.com/mxnet-scala/scala-example-ci/BertQA/static_bert_qa-0002.params\", \"static_bert_qa-0002.params\");\n",
    "download(\"https://s3.us-east-2.amazonaws.com/mxnet-scala/scala-example-ci/BertQA/static_bert_qa-symbol.json\", \"static_bert_qa-symbol.json\");\n",
    "download(\"https://s3.us-east-2.amazonaws.com/mxnet-scala/scala-example-ci/BertQA/vocab.json\", \"vocab.json\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's try to load the model and vocabulary. Please create a variable `model` by using `Model.loadModel(<model_directory>, <model_name>)` to load your model.\n",
    "\n",
    "After that, you can use `getArtifact(\"fileName\", function)` method to load the vocabulary and create `BertDataParser` class to prepare for the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "var modelName = \"static_bert_qa\";\n",
    "var modelDir = Paths.get(System.getProperty(\"java.io.tmpdir\")).resolve(\"bert\");\n",
    "// TODO: Add load model function here\n",
    "var model = Model.loadModel(modelDir, modelName);\n",
    "\n",
    "BertDataParser parser = model.getArtifact(\"vocab.json\", BertDataParser::parse);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Creating the Translator\n",
    "\n",
    "Inference in Deep Learning is the process of predicting the output for a given input based on a pre-defined model. \n",
    "Joule abstracts the whole process away from you. It can load the model, perform inference on the input, and provide \n",
    "output. Joule also allows you to provide user-defined inputs. The workflow looks like the following:\n",
    "\n",
    "![image](../examples/doc/img/workFlow.png)\n",
    "\n",
    "The red block (\"Images\") in the workflow is the input that Joule expects from you. The green block (\"Images \n",
    "bounding box\") is the output that you expect. Since Joule does not know what input to expect and what format of output that you prefer, Joule provides the `Translator` interface so you can define your own \n",
    "input and output.  \n",
    "\n",
    "The `Translator` interface encompasses the two white blocks: Pre-processing and Post-processing. The pre-processing \n",
    "component converts the user-defined input objects into an NDList, so that the `Predictor` in Joule can understand the \n",
    "input and make its prediction. Similarly, the post-processing block receives an NDList as the output from the \n",
    "`Predictor`. The post-processing block allows you to convert the output from the `Predictor` to the desired output \n",
    "format. \n",
    "\n",
    "#### Pre-processing\n",
    "\n",
    "Now, we need to convert the sentences into tokens. You can use `BertDataParser.tokenizer` to convert question and answer into tokens. Then, you can use `BertDataParser.formTokens` to create Bert Formatted tokens. Once, we have properly formatted tokens, we can use `parser.token2idx` to create the indices. \n",
    "\n",
    "In the code block below, you convert question and answer defined earlier into bert-formatted tokens, and create word types for the tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "public static float[] toFloatArray(List<? extends Number> list) {\n",
    "    float[] ret = new float[list.size()];\n",
    "    int idx = 0;\n",
    "    for (Number n : list) {\n",
    "        ret[idx++] = n.floatValue();\n",
    "    }\n",
    "    return ret;\n",
    "}\n",
    "\n",
    "// Create token lists for question and answer\n",
    "List<String> tokenQ = BertDataParser.tokenizer(question);\n",
    "List<String> tokenA = BertDataParser.tokenizer(answerMaterial);\n",
    "\n",
    "// Create Bert-formatted tokens\n",
    "List<String> tokens = BertDataParser.formTokens(tokenQ, tokenA, 384);\n",
    "\n",
    "// Convert tokens into indices in the vocabulary\n",
    "List<Integer> indexes = parser.token2idx(tokens);\n",
    "float[] indexesFloat = toFloatArray(indexes);\n",
    "\n",
    "// Get token types\n",
    "List<Float> tokenTypes = BertDataParser.getTokenTypes(tokenQ, tokenA, 384);\n",
    "float[] types = toFloatArray(tokenTypes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have everything you need, you can create an NDList, and populate all of the inputs we formatted earlier, and you will be done with pre-processing! \n",
    "\n",
    "However, you need to do this processing within an implementation of the Translator interface. Below is one implementation of the translator we have created. Please complete the TODO sections in the `processInput` section below. (HINT: use the code snippets in the previous cell to help guide you)\n",
    "\n",
    "Every translator takes in input, and returns output in the form of generic objects. In this case, the translator takes input in the form of `QAInput`, and return output as a `String`. `QAInput` is just an object that holds questions, answer and seqLength;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class QAInput {\n",
    "    private String question;\n",
    "    private String answer;\n",
    "    private int seqLength;\n",
    "\n",
    "    QAInput(String question, String answer, int seqlength) {\n",
    "        this.question = question;\n",
    "        this.answer = answer;\n",
    "        this.seqLength = seqLength;\n",
    "    }\n",
    "\n",
    "    public String getQuestion() {\n",
    "        return question;\n",
    "    }\n",
    "    \n",
    "    public String getAnswer() {\n",
    "        return answer;\n",
    "    }\n",
    "\n",
    "    public int getSeqLength() {\n",
    "        return seqLength;\n",
    "    }\n",
    "}\n",
    "\n",
    "public class BertTranslator implements Translator<QAInput, String> {\n",
    "        private BertDataParser parser;\n",
    "        private List<String> tokens;\n",
    "\n",
    "        BertTranslator(BertDataParser parser) {\n",
    "            this.parser = parser;\n",
    "        }\n",
    "\n",
    "        @Override\n",
    "        public NDList processInput(TranslatorContext ctx, QAInput input) {\n",
    "            // Pre-processing - tokenize sentence\n",
    "            // TODO: Create token lists for question and answer\n",
    "            \n",
    "            \n",
    "            \n",
    "            // TODO: Create Bert-formatted tokens\n",
    "            \n",
    "            \n",
    "            \n",
    "            // Convert tokens into indices in the vocabulary\n",
    "            \n",
    "            \n",
    "            \n",
    "            // TODO: Get token types\n",
    "            List<Float> tokenTypes = BertDataParser.getTokenTypes(tokenQ, tokenA, input.getSeqLength());\n",
    "            float[] types = Utils.toFloatArray(tokenTypes);\n",
    "            \n",
    "            \n",
    "            // TODO Calculate valid length\n",
    "            int validLength = 0;\n",
    "\n",
    "            NDManager manager = ctx.getNDManager();\n",
    "            \n",
    "            // TODO Using the manager created above, create NDArrays for the indices, types, and valid length, in that order. \n",
    "            NDArray data0 = null;\n",
    "            NDArray data1 = null;\n",
    "            NDArray data2 = null;\n",
    "\n",
    "            NDList list = new NDList(3);\n",
    "            list.add(\"data0\", data0);\n",
    "            list.add(\"data1\", data1);\n",
    "            list.add(\"data2\", data2);\n",
    "\n",
    "            return list;\n",
    "        }\n",
    "\n",
    "        @Override\n",
    "        public String processOutput(TranslatorContext ctx, NDList list) {\n",
    "            NDArray array = list.get(0);\n",
    "            NDList output = array.split(2, 2);\n",
    "            // Get the formatted logits result\n",
    "            NDArray startLogits = output.get(0).reshape(new Shape(1, -1));\n",
    "            NDArray endLogits = output.get(1).reshape(new Shape(1, -1));\n",
    "            // Get Probability distribution\n",
    "            float[] startProb = startLogits.softmax(-1).toFloatArray();\n",
    "            float[] endProb = endLogits.softmax(-1).toFloatArray();\n",
    "            int startIdx = argmax(startProb);\n",
    "            int endIdx = argmax(endProb);\n",
    "            return tokens.subList(startIdx, endIdx + 1).toString();\n",
    "        }\n",
    "\n",
    "        private static int argmax(float[] prob) {\n",
    "            int maxIdx = 0;\n",
    "            for (int i = 0; i < prob.length; i++) {\n",
    "                if (prob[maxIdx] < prob[i]) {\n",
    "                    maxIdx = i;\n",
    "                }\n",
    "            }\n",
    "            return maxIdx;\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You have created your first Translator! As you can see above, we have pre-filled the `processOutput()` that will process the `NDList` returned to a format that is favourable to you. The `processInput()` and `processOutput()` offer the flexibility to get the predictions from the model in any format you desire. \n",
    "\n",
    "\n",
    "With the Translator implemented, all there is to do is to bring up the predictor to start making predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IJava-executor-14] WARN org.apache.mxnet.engine.CachedOp - Input data2 not found, set NDArray to Shape(1) by default\n",
      "[IJava-executor-14] WARN org.apache.mxnet.engine.CachedOp - Input data0 not found, set NDArray to Shape(1) by default\n",
      "[IJava-executor-14] WARN org.apache.mxnet.engine.CachedOp - Input data1 not found, set NDArray to Shape(1) by default\n"
     ]
    }
   ],
   "source": [
    "protected void printProgress(int iteration, int index) {\n",
    "    System.out.print(\".\");\n",
    "    if (index % 80 == 79 || index == iteration - 1) {\n",
    "        System.out.println();\n",
    "    }\n",
    "}\n",
    "\n",
    "String predictResult = null;\n",
    "QAInput input = new QAInput(question, answerMaterial, 384);\n",
    "BertTranslator translator = new BertTranslator(parser);\n",
    "\n",
    "// TODO: Create a Predictor and predict the output using the predictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! It's that simple!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.3+12-LTS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
