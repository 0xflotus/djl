{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joule BERT Inference Demo\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, you'll walk through the BERT QA model trained by MXNet. \n",
    "You can provide a question and a paragraph containing the answer to the model. The model is then able to find the best answer from the answer paragraph.\n",
    "\n",
    "Example:\n",
    "```text\n",
    "Q: When did BBC Japan start broadcasting?\n",
    "```\n",
    "\n",
    "Answer paragraph:\n",
    "```text\n",
    "BBC Japan was a general entertainment channel, which operated between December 2004 and April 2006.\n",
    "It ceased operations after its Japanese distributor folded.\n",
    "```\n",
    "And it picked the right answer:\n",
    "```text\n",
    "A: December 2004\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Configure the maven repository\n",
    "The following command define the repo to fetch the Joule package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mavenRepo s3 https://joule.s3.amazonaws.com/repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Import the required library\n",
    "Please run the following command to load the Joule package and its dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%maven software.amazon.ai:joule-api:0.2.0-SNAPSHOT\n",
    "%maven org.apache.mxnet:mxnet-joule:0.2.0-SNAPSHOT\n",
    "%maven org.slf4j:slf4j-api:1.7.26\n",
    "%maven org.slf4j:slf4j-simple:1.7.26\n",
    "%maven net.java.dev.jna:jna:5.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the problem with gradle integration with Jupyter, we need to manually load MXNet pacakge from pom.\n",
    "\n",
    "Please specify the MXNet package you would like to use by changing the `<classifier>` tag. Here are the two options you can go with for Mac and Linux system.\n",
    "\n",
    "#### Mac OS\n",
    "```\n",
    "<classifier>osx-x86_64</classifier>\n",
    "```\n",
    "\n",
    "#### Ubuntu 16.04/Cent OS 7/Amazon Linux\n",
    "```\n",
    "<classifier>linux-x86_64</classifier>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "  <repositories>\n",
    "    <repository>\n",
    "      <id>joule</id>\n",
    "      <url>https://joule.s3.amazonaws.com/repo</url>\n",
    "    </repository>\n",
    "  </repositories>\n",
    "\n",
    "  <dependencies>\n",
    "    <dependency>\n",
    "      <groupId>org.apache.mxnet</groupId>\n",
    "      <artifactId>mxnet-native-mkl</artifactId>\n",
    "      <version>1.5.0-SNAPSHOT</version>\n",
    "      <classifier>osx-x86_64</classifier>\n",
    "    </dependency>\n",
    "  </dependencies>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the library that going to be used in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.charset.StandardCharsets;\n",
    "import java.nio.file.*;\n",
    "import java.util.*;\n",
    "import java.io.*;\n",
    "import software.amazon.ai.*;\n",
    "import com.google.gson.Gson;\n",
    "import com.google.gson.GsonBuilder;\n",
    "import com.google.gson.annotations.SerializedName;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Load the BertDataParser\n",
    "The Class `BertDataParser` is used to load the vocabulary that Bert Embedding being trained. Please do not change the content of the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * This is the Utility for pre-processing the data for Bert Model.\n",
    " *\n",
    " * <p>You can use this utility to parse vocabulary JSON into Java Array and Dictionary, clean and\n",
    " * tokenize sentences and pad the text\n",
    " */\n",
    "\n",
    "public class BertDataParser {\n",
    "\n",
    "    private static final Gson GSON = new GsonBuilder().create();\n",
    "    private static final Pattern PATTERN = Pattern.compile(\"(\\\\S+?)([.,?!])?(\\\\s+|$)\");\n",
    "\n",
    "    @SerializedName(\"token_to_idx\")\n",
    "    private Map<String, Integer> token2idx;\n",
    "\n",
    "    @SerializedName(\"idx_to_token\")\n",
    "    private List<String> idx2token;\n",
    "\n",
    "    /**\n",
    "    \n",
    "     * Parse the Vocabulary to JSON files [PAD], [CLS], [SEP], [MASK], [UNK] are reserved tokens.\n",
    "     *\n",
    "     * @param is the {@code InputStream} for the vocab.json\n",
    "     * @return instance of {@code BertDataParser}\n",
    "     * @throws IllegalStateException if failed read from {@code InputStream}\n",
    "     */\n",
    "    public static BertDataParser parse(InputStream is) {\n",
    "        try (Reader reader = new InputStreamReader(is, StandardCharsets.UTF_8)) {\n",
    "            return GSON.fromJson(reader, BertDataParser.class);\n",
    "        } catch (IOException e) {\n",
    "            throw new IllegalStateException(e);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Tokenize the input, split all kinds of whitespace and Separate the end of sentence symbol: .\n",
    "     * , ? !\n",
    "     *\n",
    "     * @param input The input string\n",
    "     * @return List of tokens\n",
    "     */\n",
    "    public static List<String> tokenizer(String input) {\n",
    "        List<String> ret = new LinkedList<>();\n",
    "\n",
    "        Matcher m = PATTERN.matcher(input);\n",
    "        while (m.find()) {\n",
    "            ret.add(m.group(1));\n",
    "            String token = m.group(2);\n",
    "            if (token != null) {\n",
    "                ret.add(token);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return ret;\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Pad the tokens to the required length.\n",
    "     *\n",
    "     * @param <E> the type of the List\n",
    "     * @param tokens input tokens\n",
    "     * @param padItem things to pad at the end\n",
    "     * @param num total length after padding\n",
    "     * @return List of padded tokens\n",
    "     */\n",
    "    public static <E> List<E> pad(List<E> tokens, E padItem, int num) {\n",
    "        if (tokens.size() >= num) {\n",
    "            return tokens;\n",
    "        }\n",
    "        List<E> padded = new ArrayList<>(num);\n",
    "        padded.addAll(tokens);\n",
    "        for (int i = tokens.size(); i < num; ++i) {\n",
    "            padded.add(padItem);\n",
    "        }\n",
    "        return padded;\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Form the token types List [0000...1111...000] where all questions are 0 and answers are 1.\n",
    "     *\n",
    "     * @param question question tokens\n",
    "     * @param answer answer tokens\n",
    "     * @param seqLength sequence length\n",
    "     * @return List of tokenTypes\n",
    "     */\n",
    "    public static List<Float> getTokenTypes(\n",
    "            List<String> question, List<String> answer, int seqLength) {\n",
    "        List<Float> qaEmbedded = new ArrayList<>();\n",
    "        qaEmbedded = pad(qaEmbedded, 0f, question.size() + 2);\n",
    "        qaEmbedded.addAll(pad(new ArrayList<>(), 1f, answer.size()));\n",
    "        return pad(qaEmbedded, 0f, seqLength);\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Form tokens with separation that can be used for BERT.\n",
    "     *\n",
    "     * @param question question tokens\n",
    "     * @param answer answer tokens\n",
    "     * @param seqLength sequence length\n",
    "     * @return List of tokenTypes\n",
    "     */\n",
    "    public static List<String> formTokens(\n",
    "            List<String> question, List<String> answer, int seqLength) {\n",
    "        // make BERT pre-processing standard\n",
    "        List<String> tokens = new ArrayList<>(question);\n",
    "        tokens.add(\"[SEP]\");\n",
    "        tokens.add(0, \"[CLS]\");\n",
    "        answer.add(\"[SEP]\");\n",
    "        tokens.addAll(answer);\n",
    "        tokens.add(\"[SEP]\");\n",
    "        return pad(tokens, \"[PAD]\", seqLength);\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Convert tokens to indexes.\n",
    "     *\n",
    "     * @param tokens input tokens\n",
    "     * @return List of indexes\n",
    "     */\n",
    "    public List<Integer> token2idx(List<String> tokens) {\n",
    "        List<Integer> indexes = new ArrayList<>();\n",
    "        for (String token : tokens) {\n",
    "            if (token2idx.containsKey(token)) {\n",
    "                indexes.add(token2idx.get(token));\n",
    "            } else {\n",
    "                indexes.add(token2idx.get(\"[UNK]\"));\n",
    "            }\n",
    "        }\n",
    "        return indexes;\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Convert indexes to tokens.\n",
    "     *\n",
    "     * @param indexes List of indexes\n",
    "     * @return List of tokens\n",
    "     */\n",
    "    public List<String> idx2token(List<Integer> indexes) {\n",
    "        List<String> tokens = new ArrayList<>();\n",
    "        for (int index : indexes) {\n",
    "            tokens.add(idx2token.get(index));\n",
    "        }\n",
    "        return tokens;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this point, we finish all of the preparations. Let's start writing code to do inference with this example.\n",
    "\n",
    "### Step 4 Preparing for the model and input\n",
    "\n",
    "The model would require three inputs:\n",
    "\n",
    "- word indices: The index of each word in a sentence\n",
    "- word types: The type index of the word. All Questions will be labelled as 0 and all Answers will be labelled as 1s.\n",
    "- sequence length: We need to limit the length of the input, in our case, the length is 384\n",
    "\n",
    "**Firstly, let's load the input**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var question = \"When did BBC Japan start broadcasting?\";\n",
    "var answerMaterial = \"BBC Japan was a general entertainment Channel.\\nWhich operated between December 2004 and April 2006.\\nIt ceased operations after its Japanese distributor folded.\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Secondly, we can load the model and all its artifacts**\n",
    "\n",
    "This download process may take a while based on the network speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "public void download(String url, String fileName) throws IOException {\n",
    "  URL downloadUrl = new URL(url);\n",
    "  String tempDir = System.getProperty(\"java.io.tmpdir\");\n",
    "  Path tmp = Paths.get(tempDir).resolve(\"bert\");\n",
    "  Path dest = tmp.resolve(fileName);\n",
    "  if (Files.exists(dest)) {\n",
    "    return;\n",
    "  }\n",
    "  Files.createDirectories(tmp.toAbsolutePath());\n",
    "  try (InputStream is = downloadUrl.openStream()) {\n",
    "    Files.copy(is, dest);\n",
    "  }\n",
    "}\n",
    "\n",
    "download(\"https://s3.us-east-2.amazonaws.com/mxnet-scala/scala-example-ci/BertQA/static_bert_qa-0002.params\", \"static_bert_qa-0002.params\");\n",
    "download(\"https://s3.us-east-2.amazonaws.com/mxnet-scala/scala-example-ci/BertQA/static_bert_qa-symbol.json\", \"static_bert_qa-symbol.json\");\n",
    "download(\"https://s3.us-east-2.amazonaws.com/mxnet-scala/scala-example-ci/BertQA/vocab.json\", \"vocab.json\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's try to load the model and vocabulary. Please create a variable `model` by using `Model.loadModel(<model_directory>, <model_name>)` to load your model.\n",
    "\n",
    "After that, you can use `getArtifact(\"fileName\", function)` method to load the vocabulary and create `BertDataParser` class to prepare for the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "var modelName = \"static_bert_qa\";\n",
    "var modelDir = Paths.get(System.getProperty(\"java.io.tmpdir\")).resolve(\"bert\");\n",
    "// TODO: Add load model function here\n",
    "var model = Model.loadModel(modelDir, modelName);\n",
    "\n",
    "BertDataParser parser = model.getArtifact(\"vocab.json\", BertDataParser::parse);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Preprocessing\n",
    "Then, we need to make the sentence into tokens, you can use `BertDataParser.tokenizer` to make question and answer into tokens and then convert them into indices. After that you can use `BertDataParser.formTokens` to create Bert Formatted tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.3+12-LTS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
